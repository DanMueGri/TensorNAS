{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST_NAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyadalal/Optimization_Using_Evolutionary_Algorithms/blob/master/MNIST_NAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d_q-FH0dgMQq"
      },
      "source": [
        "This example will perform character recognition through user input into the touch screen of an STM3240G-Evaluation board using the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RcNx6RbVg3cc",
        "colab": {}
      },
      "source": [
        "#%tensorflow_version 2.x\n",
        "#!apt-get install -y xxd\n",
        "\n",
        "#! pip uninstall -y tensorflow\n",
        "#! pip install -q tf-nightly\n",
        "#! pip install -q tensorflow-model-optimization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "(images_train, labels_train), (images_test, labels_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4Y2hcinVg4Ws"
      },
      "source": [
        "Importing Tensorflow allows you to use its API to load the MNIST dataset. It should be noted that we need to use TF version <1.14 as this version includes the fully connected operation version 3 which is incompatible with the micro interpreters version 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MnCKuVlVjRhX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "16e6cefc-cbf2-42f2-d349-c55de99afcaf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "test_index = 12345\n",
        "print(labels_train[test_index])\n",
        "plt.imshow(images_train[test_index], cmap='Greys')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fde8f98e668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-76bBO2rlABd"
      },
      "source": [
        "The input of the neural network needs to know the input shape that it is going to be fed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gWwrc29FlEgQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51ec1585-6e00-4a87-d409-2ce2862a727c"
      },
      "source": [
        "input_shape = images_train.shape\n",
        "print(\"{} images, each with shape of {} pixels x {} pixels\".format(input_shape[0], input_shape[1], input_shape[2]))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 images, each with shape of 28 pixels x 28 pixels\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zn-3cvuymAWT"
      },
      "source": [
        "The input shape for the model must be reshaped to 4D as the current shape does not show that each pixel is a 1D array where only the greyscale value (0-255) is stored. The input tensor's shape will be 3D as it will take a single-channel image. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qOZnWmzUmTuI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0a293b8-9913-44ca-b5bf-ca1a01141eaf"
      },
      "source": [
        "images_train = images_train.reshape(images_train.shape[0], images_train.shape[1], images_train.shape[2], 1)\n",
        "images_test = images_test.reshape(images_test.shape[0], images_test.shape[1], images_test.shape[2], 1)\n",
        "input_tensor_shape = (images_test.shape[1], images_test.shape[2], 1)\n",
        "print(\"Input shape: {}\".format(input_shape))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mjPMYztkm0tg"
      },
      "source": [
        "The greyscale values stores in the images' pixels are 8 bit values and need to be normalized into floats between 0-1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "adD13BYinHlG",
        "colab": {}
      },
      "source": [
        "images_train = images_train.astype('float32')\n",
        "images_test = images_test.astype('float32')\n",
        "images_train /= 255\n",
        "images_test /= 255"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4dxhv2gR3fU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Counter initialization for iteration count\n",
        "count=0"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS7vq9qKUuPS",
        "colab_type": "text"
      },
      "source": [
        "Create some classes for storing the layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HjEwEo9Uq09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from enum import Enum, auto\n",
        "import sys\n",
        "\n",
        "class Conv2DArgs(Enum):\n",
        "  'Args needed for creating Conv2DArgs layer, list not complete'\n",
        "  FILTERS = auto()\n",
        "  KERNEL_SIZE = auto()\n",
        "  STRIDES = auto()\n",
        "  INPUT_SIZE = auto()\n",
        "\n",
        "class MaxPool2DArgs(Enum):\n",
        "  'Args needed for creating MaxPool2D layer, list not complete'\n",
        "  POOL_SIZE = auto()\n",
        "  STRIDES = auto()\n",
        "\n",
        "class ReshapeArgs(Enum):\n",
        "  'Args needed for creating Reshape layer'\n",
        "  TARGET_SHAPE = auto()\n",
        "\n",
        "class DenseArgs(Enum):\n",
        "  'Args needed for creating Dense layer, list not complete'\n",
        "  UNITS = auto()\n",
        "  ACTIVATION = auto()\n",
        "\n",
        "class DropoutArgs(Enum):\n",
        "  'Args needed for creating Dropout layer, list not complete'\n",
        "  RATE = auto()\n",
        "\n",
        "class ModelLayer:\n",
        "  'Common layer properties'\n",
        "\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.args = {}\n",
        "\n",
        "class Conv2DLayer(ModelLayer):\n",
        "\n",
        "  def __init__(self, filters, kernel_size, strides, input_size):\n",
        "    super().__init__(\"Conv2D\")\n",
        "    self.args[Conv2DArgs.FILTERS.name] = filters\n",
        "    self.args[Conv2DArgs.KERNEL_SIZE.name] = kernel_size\n",
        "    self.args[Conv2DArgs.STRIDES.name] = strides\n",
        "    self.args[Conv2DArgs.INPUT_SIZE.name] = input_size \n",
        "\n",
        "  def getkeraslayer(self):\n",
        "    return keras.layers.Conv2D(\n",
        "        self.args.get(Conv2DArgs.FILTERS.name), \n",
        "        kernel_size=self.args.get(Conv2DArgs.KERNEL_SIZE.name), \n",
        "        strides=self.args.get(Conv2DArgs.STRIDES.name), \n",
        "        input_shape=self.args.get(Conv2DArgs.INPUT_SIZE.name))\n",
        "\n",
        "class MaxPool2DLayer(ModelLayer):\n",
        "\n",
        "  def __init__(self, pool_size, strides):\n",
        "    super().__init__(\"MaxPool2D\")\n",
        "    self.args[MaxPool2DArgs.POOL_SIZE.name] = pool_size\n",
        "    self.args[MaxPool2DArgs.STRIDES.name] = strides \n",
        "\n",
        "  def getkeraslayer(self):\n",
        "    return keras.layers.MaxPool2D(\n",
        "        pool_size=self.args.get(MaxPool2DArgs.POOL_SIZE.name),\n",
        "        strides=self.args.get(MaxPool2DArgs.STRIDES.name)\n",
        "    )\n",
        "\n",
        "class MaxPool3DLayer(MaxPool2DLayer):\n",
        "\n",
        "  def __init__(self, pool_size, strides):\n",
        "    super(MaxPool2DLayer, self).__init__(\"MaxPool3D\")\n",
        "    super().__init__(pool_size, strides)\n",
        "    \n",
        "  def getkeraslayer(self):\n",
        "    return keras.layers.MaxPool3D(\n",
        "        pool_size=self.args.get(MaxPool2DArgs.POOL_SIZE.name),\n",
        "        strides=self.args.get(MaxPool2DArgs.STRIDES.name)\n",
        "    )\n",
        "  \n",
        "class ReshapeLayer(ModelLayer):\n",
        "\n",
        "  def __init__(self, target_shape):\n",
        "    super().__init__(\"Reshape\")\n",
        "    self.args[ReshapeArgs.TARGET_SHAPE.name] = target_shape\n",
        "\n",
        "  def getkeraslayer(self):\n",
        "    return keras.layers.Reshape(self.args.get(ReshapeArgs.TARGET_SHAPE.name))\n",
        "\n",
        "class DenseLayer(ModelLayer):\n",
        "\n",
        "  def __init__(self, units, activation):\n",
        "    super().__init__(\"Dense\")\n",
        "    self.args[DenseArgs.UNITS.name] = units\n",
        "    self.args[DenseArgs.ACTIVATION.name] = activation\n",
        "\n",
        "  def getkeraslayer(self):\n",
        "    return keras.layers.Dense(self.args.get(DenseArgs.UNITS.name), \n",
        "                              activation=self.args.get(DenseArgs.ACTIVATION.name))\n",
        "\n",
        "class FlattenLayer(ModelLayer):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__(\"Flatten\")\n",
        "\n",
        "  def getkeraslayer(self):\n",
        "    return keras.layers.Flatten()\n",
        "\n",
        "class Dropout(ModelLayer):\n",
        "\n",
        "  def __init__(self, rate):\n",
        "    super().__init__(\"Dropout\")\n",
        "    self.args[DropoutArgs.RATE.name] = rate\n",
        "  \n",
        "  def getkeraslayer(self):\n",
        "    return keras.layers.Dropout(self.args.get(DropoutArgs.RATE.name))\n",
        "  \n",
        "class Model:\n",
        "\n",
        "  def __init__(self, json, optimizer='adam', \n",
        "               loss='sparse_categorical_crossentropy', metrics=['accuracy']):\n",
        "    self.optimizer = optimizer\n",
        "    self.loss = loss\n",
        "    self.metrics = metrics\n",
        "    self.layers = []\n",
        "\n",
        "    for x in range(len(json.keys())):\n",
        "      layer = json.get(str(x))\n",
        "      name = layer.get('name')\n",
        "      args = layer.get('args')\n",
        "      if name == \"Conv2D\":\n",
        "        filters = args.get(Conv2DArgs.FILTERS.name)\n",
        "        kernel_size = tuple(args.get(Conv2DArgs.KERNEL_SIZE.name))\n",
        "        strides = args.get(Conv2DArgs.STRIDES.name, (1,1))\n",
        "        input_size = tuple(args.get(Conv2DArgs.INPUT_SIZE.name))\n",
        "        self.layers.append(Conv2DLayer(filters, kernel_size, strides, input_size))\n",
        "        print(\"Created {} layer with {} filters, {} kernel size, {} stride size and {} input size\".format(\n",
        "          name, filters, kernel_size, strides, input_size\n",
        "        ))\n",
        "      elif name == \"MaxPool2D\" or name == \"MaxPool3D\":\n",
        "        pool_size = args.get(MaxPool2DArgs.POOL_SIZE.name)\n",
        "        strides = args.get(MaxPool2DArgs.STRIDES.name, None)\n",
        "        if name == \"MaxPool2D\":\n",
        "          self.layers.append(MaxPool2DLayer(pool_size, strides))\n",
        "          print(\"Created {} layer with {} pool size and {} stride size\".format(\n",
        "              name, pool_size, strides\n",
        "          ))\n",
        "        else:\n",
        "          self.layers.append(MaxPool3DLayer(pool_size, strides))\n",
        "          print(\"Created {} layer with {} pool size and {} stride size\".format(\n",
        "              name, pool_size, strides\n",
        "          ))\n",
        "      elif name == \"Reshape\":\n",
        "        target_shape = args.get(ReshapeArgs.TARGET_SHAPE.name)\n",
        "        self.layers.append(ReshapeLayer(target_shape))\n",
        "        print(\" Created {} layer with {} target shape\".format(name, target_shape))\n",
        "      elif name == \"Dense\":\n",
        "        units = args.get(DenseArgs.UNITS.name)\n",
        "        activation = getattr(tf.nn, args.get(DenseArgs.ACTIVATION.name))\n",
        "        self.layers.append(DenseLayer(units, activation))\n",
        "        print(\"Created {} layer with {} units and {} activation\".format(name, units, activation))\n",
        "      elif name == \"Flatten\":\n",
        "        self.layers.append(FlattenLayer())\n",
        "        print(\"Create {} layer\".format(name))\n",
        "      elif name == \"Dropout\":\n",
        "        rate = args.get(DropoutArgs.RATE.name)\n",
        "        self.layers.append(Dropout(rate))\n",
        "        print(\"Created {} layers with {} rate\".format(name, rate))\n",
        "\n",
        "  def gettfmodel(self):\n",
        "    model = keras.Sequential()\n",
        "    for layer in self.layers:\n",
        "      model.add(layer.getkeraslayer())\n",
        "\n",
        "    model.compile(optimizer=self.optimizer, loss=self.loss, metrics=self.metrics)\n",
        "    return model\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02dHk-beR3fi",
        "colab_type": "text"
      },
      "source": [
        "Random Number Generator for generating random combination of input parameters "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEMJuERDR3fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random Number generator \n",
        "import random\n",
        "\n",
        "# I figure we can just call the layers '0', '1',...etc and this \"name\" is then the layer's index in the model\n",
        "Model_Configuration1= {\n",
        "        \n",
        "    0: {\n",
        "      'name': 'Conv2D',\n",
        "      'args':  {\n",
        "          Conv2DArgs.FILTERS.name: 28,\n",
        "          Conv2DArgs.KERNEL_SIZE.name: [3,3],\n",
        "          Conv2DArgs.INPUT_SIZE.name: [28,28,1]\n",
        "          }\n",
        "    }, \n",
        "    1: {\n",
        "      'name': 'MaxPool2D',\n",
        "      'args':  {\n",
        "          MaxPool2DArgs.POOL_SIZE.name: [2, 2],\n",
        "        }\n",
        "    },\n",
        "    2: {\n",
        "      'name': 'Flatten'\n",
        "    },\n",
        "    3: {\n",
        "      'name': 'Dense',\n",
        "      'args': {\n",
        "          DenseArgs.UNITS.name: 128,\n",
        "          DenseArgs.ACTIVATION.name: \"relu\"\n",
        "        }   \n",
        "    },\n",
        "    4: {\n",
        "        'name': 'Dropout',\n",
        "        'args':{\n",
        "            DropoutArgs.RATE.name: 0.2\n",
        "        }\n",
        "    },\n",
        "    5: {\n",
        "        'name' : 'Dense',\n",
        "        'args': {\n",
        "        DenseArgs.UNITS.name: 128,\n",
        "        DenseArgs.ACTIVATION.name: \"softmax\"\n",
        "      }   \n",
        "    } \n",
        "}\n",
        "\n",
        "Model_Configuration4 = {\n",
        "    0: {\n",
        "        'name': 'Conv2D',\n",
        "        'args': {\n",
        "          Conv2DArgs.FILTERS.name: 12,\n",
        "          Conv2DArgs.KERNEL_SIZE.name: [3,3],\n",
        "          Conv2DArgs.STRIDES.name: [2,2],\n",
        "          Conv2DArgs.INPUT_SIZE.name: [28,28,1]\n",
        "          }\n",
        "    },\n",
        "    1: {\n",
        "        'name': 'Reshape',\n",
        "        'args': {\n",
        "            ReshapeArgs.TARGET_SHAPE.name: [13,13,12,1]\n",
        "        }\n",
        "    },\n",
        "    2: {\n",
        "        'name': \"MaxPool3D\",\n",
        "        'args':  {\n",
        "          MaxPool2DArgs.POOL_SIZE.name: [6, 3, 3],\n",
        "        }\n",
        "    },\n",
        "    3: {\n",
        "        'name': 'Flatten'\n",
        "    },\n",
        "    4: {\n",
        "        'name' : 'Dense',\n",
        "        'args': {\n",
        "        DenseArgs.UNITS.name: 128,\n",
        "        DenseArgs.ACTIVATION.name: \"softmax\"\n",
        "      } \n",
        "    }\n",
        "}\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCLFswlQR3f2",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvLw_LooR3gQ",
        "colab_type": "text"
      },
      "source": [
        "Input configuration JSON file is used to store list of different combination of Input parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN0MB-jbR3gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Appending procedure JSON\n",
        "import os\n",
        "import random\n",
        "\n",
        "def write_json(json_model, filename):\n",
        "  with open(\"{}.json\".format(filename), mode='w+') as f:\n",
        "      f.write(json.dumps(json_model, indent=2))\n",
        "\n",
        "def load_json(filename):\n",
        "  if os.path.isfile(\"{}.json\".format(filename)):\n",
        "    with open(\"{}.json\".format(filename)) as f:\n",
        "        return json.load(f)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm95GeulR3gc",
        "colab_type": "text"
      },
      "source": [
        "Loading the parameters from JSON file as input to our Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL6LZ1XfR3gf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "265ce892-0e81-4767-e1a0-f01b39eaf6e9"
      },
      "source": [
        "# # get model configuration params from our json file which is being appended\n",
        "import json\n",
        "\n",
        "write_json(Model_Configuration1, \"test\")\n",
        "\n",
        "test_read = load_json(\"test\")\n",
        "\n",
        "test_model = Model(test_read)\n",
        "\n",
        "tf_model = test_model.gettfmodel()\n",
        "\n",
        "write_json(Model_Configuration4, \"test4\")\n",
        "\n",
        "test_read4 = load_json(\"test4\")\n",
        "\n",
        "test_model4 = Model(test_read4)\n",
        "\n",
        "tf_model4 = test_model4.gettfmodel()\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "\n",
        "history = tf_model.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "tf_model.summary()\n",
        "history4 = tf_model4.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "tf_model4.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created Conv2D layer with 28 filters, (3, 3) kernel size, (1, 1) stride size and (28, 28, 1) input size\n",
            "Created MaxPool2D layer with [2, 2] pool size and None stride size\n",
            "Create Flatten layer\n",
            "Created Dense layer with 128 units and <function relu at 0x7fde9c317bf8> activation\n",
            "Created Dropout layers with 0.2 rate\n",
            "Created Dense layer with 128 units and <function softmax_v2 at 0x7fde9acbebf8> activation\n",
            "Created Conv2D layer with 12 filters, (3, 3) kernel size, [2, 2] stride size and (28, 28, 1) input size\n",
            " Created Reshape layer with [13, 13, 12, 1] target shape\n",
            "Created MaxPool3D layer with [6, 3, 3] pool size and None stride size\n",
            "Create Flatten layer\n",
            "Created Dense layer with 128 units and <function softmax_v2 at 0x7fde9acbebf8> activation\n",
            "Epoch 1/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.3492 - accuracy: 0.9047\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.1152 - accuracy: 0.9659\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0784 - accuracy: 0.9764\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0598 - accuracy: 0.9818\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0474 - accuracy: 0.9853\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0388 - accuracy: 0.9876\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 3s 5ms/step - loss: 0.0335 - accuracy: 0.9897\n",
            "Epoch 8/10\n",
            "148/600 [======>.......................] - ETA: 2s - loss: 0.0248 - accuracy: 0.9918"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jdxlMTZvbaU8",
        "colab": {}
      },
      "source": [
        "# get model configuration params from our json file\n",
        "# import json \n",
        "# with open('Model_Configuration.json') as example_data:\n",
        "#     data = json.load(example_data)\n",
        "# print(data['layer1']['layer1_name'])\n",
        "# int(data['layer1']['param1'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "A3oXnIHunXvs"
      },
      "source": [
        "Now the convolutional NN that we will use to classify the input images taken from the touch screen will have the following layer structure\n",
        "\n",
        "1. Conv2D\n",
        "2. MaxPooling2D\n",
        "3. Flatten\n",
        "4. Dense\n",
        "5. Dropout\n",
        "11. Dense\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k-2aWbOirRCy",
        "colab": {}
      },
      "source": [
        "#layer types and shapes changed in each model\n",
        "\n",
        "#import tensorflow_model_optimization as tfmot\n",
        "\n",
        "#quantize_model = tfmot.quantization.keras.quantize_model\n",
        "model = keras.Sequential()\n",
        "\n",
        "if (data[count]['layer1']['layer1_name']=='Conv2D'):\n",
        "    model.add(keras.layers.Conv2D(int(data[count]['layer1']['param1']), kernel_size=(int(data[count]['layer1']['param2']),int(data[count]['layer1']['param3'])), input_shape=input_tensor_shape))\n",
        "if (data[count]['layer2']['layer2_name']=='Maxpool'):\n",
        "    model.add(keras.layers.MaxPooling2D(pool_size=(int(data[count]['layer2']['param1']),int(data[count]['layer2']['param2']))))         \n",
        "model.add(keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
        "model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(10,activation=tf.nn.softmax))\n",
        "\n",
        "\n",
        "#quantized_model5 = quantize_model(model5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N5CLXe63rRPf"
      },
      "source": [
        "The Conv2D layer extracts features from the input image using filters that slide across the input image. In this case we will use 28 different filters to extract a large number of unique features that will then be used to classify each image in the later layers. Thus the output of this layer will have the shape (28, 28, 1, 28)\n",
        "\n",
        "MaxPooling2D is used to reduce the output size of the convolutional layer by reducing each 2 x 2 unique chunk of the output down in to a singular value, this reducing the output's size by a factor of 4. This will reduce our (28, 28, 1, 28) tensor down to a (7, 7, 1, 28) tensor.\n",
        "\n",
        "The Flatten layer then takes this 2D array (our image) and shapes it into a single dimension (1372).\n",
        "\n",
        "The following Dense layer reduces the input 1372 values down into 128 classes, taking the first steps in classifying the image into on of the 10 output classes (0-9). This is done using the relu activation function.\n",
        "\n",
        "The Dropout layer sets 20% of the tensor's values to 0 so as to reduce overfitting.\n",
        "\n",
        "Finally the last Dense layer reduces the output value down to the 10 classes, each representing a digit between 0 and 9. This is done using the softmax activation function which makes the outputs a set of probabilities summing to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NrG75fkHxdkN"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RXWfgL0LxS3o",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#quantized_model5.compile(optimizer='adam',\n",
        "              #loss='sparse_categorical_crossentropy',\n",
        "              #metrics=['accuracy'])\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 10\n",
        "\n",
        "print(\"Model 1\")\n",
        "history = model.fit(x=images_train,y=labels_train, epochs=epochs, batch_size=batch_size)\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fNtcEcKuxgYb"
      },
      "source": [
        "Now we can evaluate our trained model using the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D4zrA9hNxkAC",
        "colab": {}
      },
      "source": [
        "res = model.evaluate(images_test, labels_test)\n",
        "print(\"Model1 has an accuracy of {0:.2f}%\".format(res[1] * 100))\n",
        "\n",
        "# Adding the results to JSON file\n",
        "stringlist = []\n",
        "li =[]\n",
        "model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "for st in stringlist:\n",
        "    li.append(st)\n",
        "    \n",
        "result={\n",
        "    'Iteration': str(count),\n",
        "    'Accuracy is:' : str(res[1] * 100),\n",
        "     '':str(li[16])\n",
        "    \n",
        "}\n",
        "# with open(\"Objectives.json\", \"w\") as jsonFile:\n",
        "#     json.dump(result, jsonFile)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NrlEuWbR3hU",
        "colab_type": "text"
      },
      "source": [
        "Writing our final results back to our JSON file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBycYjsqR3hX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Appending procedure JSON\n",
        "import os\n",
        "a = []\n",
        "if not os.path.isfile(\"/Users/priyadalal/Desktop/OutputObjective.json\"):\n",
        "    a.append(result)\n",
        "    with open(\"/Users/priyadalal/Desktop/OutputObjective.json\", mode='w') as f:\n",
        "        f.write(json.dumps(a, indent=2))\n",
        "else:\n",
        "    with open(\"/Users/priyadalal/Desktop/OutputObjective.json\") as feedsjson:\n",
        "        feeds = json.load(feedsjson)\n",
        "\n",
        "    feeds.append(result)\n",
        "    with open(\"/Users/priyadalal/Desktop/OutputObjective.json\", mode='w') as f:\n",
        "        f.write(json.dumps(feeds, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEjsGW18R3he",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Updating our counter on completing the Iteration \n",
        "count=count+1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}